import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt

df = pd.read_csv("/content/sample_data/biased_gender_loans.csv")
df.head(5)

women_loans = df[df['sex'] == 'Woman']
men_loans = df[df['sex'] == 'Man']

sns.kdeplot(men_loans['salary'], c = "r", label = "men")
sns.kdeplot(women_loans['salary'], c = "b", label = "women")
plt.legend()
plt.title("Distribution of Salaries between Men and Women")

men_loans_given = men_loans[men_loans['bank_loan'] == 'Yes']['bank_loan'].count()
men_loans_not_given = men_loans[men_loans['bank_loan'] == 'No']['bank_loan'].count()
women_loans_given = women_loans[women_loans['bank_loan'] == 'Yes']['bank_loan'].count()
women_loans_not_given = women_loans[women_loans['bank_loan'] == 'No']['bank_loan'].count()

data = {
    'Loan Status': ['Loan Given', 'Loan Not Given'] * 2,
    'Count': [men_loans_given, men_loans_not_given, women_loans_given, women_loans_not_given],
    'Gender': ['Men'] * 2 + ['Women'] * 2
}

df = pd.DataFrame(data)

sns.barplot(data=df, x='Loan Status', y='Count', hue='Gender')
plt.show()


w_loans_given = women_loans[women_loans['bank_loan'] == 'Yes']
m_loans_given = men_loans[men_loans['bank_loan'] == 'Yes']


sns.kdeplot(w_loans_given['salary'], c = 'b', label = 'Women')
sns.kdeplot(m_loans_given['salary'], c = 'r', label = 'Men')
plt.legend()

////////////////////////////////////////////////////////////////////LAB 2////////////////////////////////////////////////////////////////


import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score


df = pd.read_csv("biased_gender_loans.csv")
df.head()


X = df[["salary", "years_exp"]]
y = df["bank_loan"]
sensitive = df["sex"]


# Encode target and sensitive attribute
y = LabelEncoder().fit_transform(y)       # Yes/No → 1/0
sensitive = LabelEncoder().fit_transform(sensitive) # Man/Woman → 1/0

# Split dataset
X_train, X_test, y_train, y_test, sens_train, sens_test = train_test_split(
    X, y, sensitive, test_size=0.3, random_state=42
)



clf = LogisticRegression(max_iter=1000)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)


accuracy = accuracy_score(y_test, y_pred)
print("Model Accuracy:", accuracy)


y_pred_binary = y_pred

parity_rates = {}
for group in np.unique(sens_test):
    idx = sens_test == group
    parity_rates[group] = np.mean(y_pred_binary[idx])

print("Demographic Parity Rates:", parity_rates)

dp_diff = max(parity_rates.values()) - min(parity_rates.values())
print("Demographic Parity Difference:", dp_diff)


import matplotlib.pyplot as plt
plt.bar(["Male", "Female"], parity_rates.values(), color=["blue", "pink"])
plt.title("Demographic Parity by Gender")
plt.ylabel("P(Predicted Loan = Yes)")
plt.show()


///////////////////////////////////////////////////////////////////LAB 3/////////////////////////////////////////////////////////////////




import pandas as pd
import matplotlib.pyplot as plt
df=pd.read_csv('Financial_Loan_Access_Dataset.csv')
df.head()



df['Approved'] = df['Loan_Approved'].map({'Approved' : 1, 'Denied' : 0})
df.groupby('Gender')['Approved'].mean()



df.groupby('Gender').size()


from matplotlib import pyplot as plt
import seaborn as sns
plt.subplot(2, 2, 1)
sns.boxplot(x = df['Income'], y=df['Gender'])
plt.subplot(2, 2, 2)
sns.boxplot(x = df['Credit_Score'], y=df['Gender'])
plt.subplot(2, 2, 3)
sns.boxplot(x = df['Age'], y=df['Gender'])
plt.subplot(2, 2, 4)
sns.boxplot(x = df['Loan_Amount'], y=df['Gender'])
plt.tight_layout()
plt.show()


genders = ['Male', 'Female', 'Non-binary']
columns = ['Employment_Type','Education_Level','Citizenship_Status','Language_Proficiency','Disability_Status','Criminal_Record']
for j in columns:
    for i in range(len(genders)):
        plt.subplot(1, 3, i + 1)
        df[df['Gender'] == genders[i]][j].value_counts().plot(kind = 'bar')
        plt.title(j)
        plt.tight_layout()
    plt.show()


contingency = pd.crosstab(df['Gender'], df['Loan_Approved'])


from scipy.stats import chi2_contingency
chi2, p, dof, ex = chi2_contingency(contingency)
print(f"p-value={p}")

////////////////////////////////////////////////////////////////////LAB 4 //////////////////////////////////////////////////////////////




import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.preprocessing import LabelEncoder

from sklearn.metrics import r2_score, mean_squared_error


df = pd.read_csv(r"C:\Users\Tuf_F15\Desktop\college PDF\4th-SEM7\AIE\LABS\biased_gender_loans.csv")  # adjust path if needed
print("Dataset loaded successfully!")
print(df.head())

for col in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])

print("\nEncoded dataset preview:")
print(df.head())

target_col = 'bank_loan'
X = df.drop(columns=[target_col])
y = df[target_col]


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)


y_pred = model.predict(X_test)

print("\nModel training complete!")
print(f"Number of features: {X_train.shape[1]}")


acc = accuracy_score(y_test, y_pred)
print(f"Classification Accuracy: {acc:.4f}")
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))


protected_attr = 'sex' 


from sklearn.metrics import precision_score
from fairlearn.metrics import MetricFrame, selection_rate, true_positive_rate

# Extract sensitive feature from test set
sensitive_test = X_test[protected_attr]

# Create MetricFrame to evaluate per group
metrics = {
    'TPR': true_positive_rate,
    'Selection Rate': selection_rate,
    'Precision': precision_score
}

mf = MetricFrame(metrics=metrics, y_true=y_test, y_pred=y_pred, sensitive_features=sensitive_test)
print("Metrics by group:\n", mf.by_group)




# 1. Equal Opportunity Difference
equal_opp_diff = mf.difference(method='between_groups')['TPR']

# 2. Disparate Impact Ratio (80% rule)
dir_ratio = mf.ratio(method='between_groups')['Selection Rate']

# 3. Predictive Parity Difference
predictive_parity_diff = mf.difference(method='between_groups')['Precision']

print("\nFairness Metrics:")
print(f"Equal Opportunity Difference: {equal_opp_diff:.4f}")
print(f"Disparate Impact Ratio: {dir_ratio:.4f}")
print(f"Predictive Parity Difference: {predictive_parity_diff:.4f}")

# Optional threshold check
if dir_ratio < 0.8:
    print("Model may violate the 80% fairness rule (DIR < 0.8).")


////////////////////////////////////////////////////////////////////LAB 5 /////////////////////////////////////////////////////////////



from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from lime.lime_tabular import LimeTabularExplainer
import numpy as np

iris = load_iris()
X = iris.data
y = iris.target

feature_names = iris.feature_names
class_names = iris.target_names

# 2. Train model
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

from matplotlib import pyplot as plt
probs = model.predict_proba([X_test[10]])[0]
classes = iris.target_names

# Print them
print("Prediction probabilities:")
for c, p in zip(classes, probs):
    print(f"{c}: {p:.3f}")

# Optional: visualize them
plt.bar(classes, probs, color='skyblue')
plt.ylabel("Probability")
plt.title("Prediction probabilities for sample")
plt.show()

explainer = LimeTabularExplainer(
    X_train,
    feature_names=feature_names,
    class_names=class_names,
    discretize_continuous=True
)

exp = explainer.explain_instance(X_test[i], model.predict_proba, num_features=4, top_labels=3)

print("True class:", iris.target_names[y_test[i]])
print("Predicted class:", iris.target_names[model.predict([X_test[i]])[0]])



///////////////////////////////////////////////////LAB 6 ///////////////////////////////////////////////////////////////////////////////



import shap
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# 1. Load the Iris dataset
iris = load_iris(as_frame=True)
X = iris.data
y = iris.target


X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)


explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)
shap.summary_plot(shap_values, X_test, feature_names=X.columns)



////////////////////////////////////////////////////////////////LAB 7///////////////////////////////////////////////////////////////////




import pandas as pd
import numpy as anp
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score
import shap
shap.initjs()   # for interactive visualizations


df = pd.read_csv(r"C:\Users\Tuf_F15\Desktop\college PDF\4th-SEM7\AIE\LABS\UCI_Adult_Income.csv")
df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
print("Dataset shape:", df.shape)
print(df.head())


df.columns = df.columns.str.strip()
for col in df.select_dtypes(include=['object']).columns:
    df[col] = df[col].str.strip()
df = df[(df != '?').all(axis=1)]
print("After cleaning:", df.shape)




categorical_cols = df.select_dtypes(include=['object']).columns
le = LabelEncoder()
for col in categorical_cols:
    df[col] = le.fit_transform(df[col])
print(df.head())


X = df.drop('class', axis=1)
y = df['class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


model = DecisionTreeClassifier(max_depth=5, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))


explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)
shap_values_class_1 = shap_values[:, :, 1]
print(f"Original 3D SHAP array shape: {shap_values.shape}")
print(f"Sliced 2D SHAP array for Class 1 shape: {shap_values_class_1.shape}")
print(f"X_test shape: {X_test.shape}")
print("Displaying SHAP Beeswarm Plot for Class 1...")
shap.summary_plot(shap_values_class_1, X_test)
print("Displaying SHAP Bar Plot for Class 1...")
shap.summary_plot(shap_values_class_1, X_test, plot_type="bar")


//////////////////////////////////////////////LAB 8 ////////////////////////////////////////////////////////////////////////////////////


import pandas as pd
import numpy as np


df = pd.read_csv(r"C:\Users\Tuf_F15\Desktop\college PDF\4th-SEM7\AIE\LABS\biased_gender_loans.csv")

def add_laplace_noise(value, sensitivity, epsilon):
  b = sensitivity / epsilon
  noise = np.random.laplace(loc=0, scale=b)
  return value + noise


column_to_count = 'years_exp'

true_count = (df[column_to_count] > 20).sum()

sensitivity = 1

epsilon = 1.0

noisy_count = add_laplace_noise(true_count, sensitivity, epsilon)


print(f"True count of '{column_to_count}': {true_count}")
print(f"Noisy count of '{column_to_count}' (epsilon={epsilon}): {noisy_count}")

///////////////////////////////////////////////////////////////////////LAB 9///////////////////////////////////////////////////////////





import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression as SklearnLogisticRegression
from sklearn.metrics import accuracy_score
import warnings

# Import the DP model
from diffprivlib.models import LogisticRegression as DPLogisticRegression

# Suppress warnings for cleaner output (DP-models can be chatty)
warnings.filterwarnings('ignore')

print("Libraries imported successfully.")


iris = load_iris()
X = iris.data
y = iris.target



# You MUST scale your data for most DP algorithms to work correctly.
# This bounds the data, which is essential for calculating sensitivity.
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"Data prepared: {X_train_scaled.shape[0]} training samples, {X_test_scaled.shape[0]} test samples.")



# This is your "Epsilon = infinity" (no privacy) benchmark
baseline_model = SklearnLogisticRegression(max_iter=1000)
baseline_model.fit(X_train_scaled, y_train)
baseline_accuracy = baseline_model.score(X_test_scaled, y_test)

print(f"\nBaseline (Non-Private) Accuracy: {baseline_accuracy * 100:.2f}%")


epsilon_values = [0.01, 0.1, 0.5, 1.0, 5.0, 10.0]
dp_accuracies = []
print(f"\nStarting DP experiment for epsilon values: {epsilon_values}")



for epsilon in epsilon_values:
    # Create the Differentially Private Logistic Regression model
    # We pass epsilon directly to it.
    dp_model = DPLogisticRegression(epsilon=epsilon, max_iter=1000)
    dp_model.fit(X_train_scaled, y_train)
    accuracy = dp_model.score(X_test_scaled, y_test)
    dp_accuracies.append(accuracy)
    print(f"  Epsilon = {epsilon:5.2f} | Accuracy = {accuracy * 100:.2f}%")
print("Experiment complete.")


plt.figure(figsize=(10, 6))

# Plot the accuracy for each epsilon value
plt.plot(epsilon_values, dp_accuracies, marker='o', linestyle='-', label='DP-Logistic Regression')

# Plot the non-private baseline as a horizontal line
plt.axhline(y=baseline_accuracy, color='r', linestyle='--',
            label=f'Baseline (No DP) Accuracy: {baseline_accuracy*100:.2f}%')

# Add labels and title
plt.title('Privacy-Accuracy Trade-off on Iris Dataset')
plt.xlabel('Epsilon (Privacy Budget)')
plt.ylabel('Model Accuracy')
# Use a log scale for the x-axis to see the effect of small epsilons better
plt.xscale('log')
plt.legend()
plt.grid(True, which="both", ls="--")

# Show the plot
print("\nDisplaying plot...")
plt.show()

///////////////////////////////////////////////////////////////////////LAB 10 ////////////////////////////////////////////////////////




import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score


print("--- 1. Loading and Splitting Data ---")
# Load the Iris dataset
iris = load_iris()
X = iris.data
y = iris.target
X_target, X_shadow, y_target, y_shadow = train_test_split(
    X, y, test_size=0.5, random_state=42, stratify=y
)
X_target_train, X_target_test, y_target_train, y_target_test = train_test_split(
    X_target, y_target, test_size=0.5, random_state=42, stratify=y_target
)
X_shadow_train, X_shadow_test, y_shadow_train, y_shadow_test = train_test_split(
    X_shadow, y_shadow, test_size=0.5, random_state=42, stratify=y_shadow
)
# Note: The Iris dataset is very small (150 rows).
# This means each of our 4 datasets has only ~37 samples.
# An attack on a real, large dataset would be much more effective.
print(f"Target Train (Members) shape: {X_target_train.shape}")
print(f"Target Test (Non-Members) shape: {X_target_test.shape}")
print(f"Shadow Train shape: {X_shadow_train.shape}")
print(f"Shadow Test shape: {X_shadow_test.shape}\n")



print("--- 2. Training Target Model (Victim) ---")
# This is the model we are trying to attack.
# It is only trained on its *own* training data.
target_model = LogisticRegression(max_iter=1000, random_state=42)
target_model.fit(X_target_train, y_target_train)
print("Target model trained.\n")




print("--- 3. Training Shadow Model (Attacker's Simulator) ---")
# The attacker trains this model to create a dataset to train their *attack* model.
# It's trained on separate, "shadow" data.
shadow_model = LogisticRegression(max_iter=1000, random_state=42)
shadow_model.fit(X_shadow_train, y_shadow_train)
print("Shadow model trained.\n")



print("--- 4. Creating Training Set for Attack Model ---")
# We use the SHADOW model to build a dataset for our ATTACK model.
# We get its confidence scores for data it *was* trained on (members)...
shadow_train_proba = shadow_model.predict_proba(X_shadow_train)
shadow_train_labels = np.ones(len(X_shadow_train))  # Label = 1 (is_member)

# ...and for data it *was not* trained on (non-members).
shadow_test_proba = shadow_model.predict_proba(X_shadow_test)
shadow_test_labels = np.zeros(len(X_shadow_test))   # Label = 0 (is_not_member)

# Combine these to create the training set for the attack model
X_attack_train = np.concatenate((shadow_train_proba, shadow_test_proba), axis=0)
y_attack_train = np.concatenate((shadow_train_labels, shadow_test_labels), axis=0)

print(f"Attack training data (X) shape: {X_attack_train.shape}")
print(f"Attack training labels (y) shape: {y_attack_train.shape}\n")




print("--- 5. Training the Attack Model ---")
# This model learns to distinguish between a "member" confidence
# vector and a "non-member" confidence vector.
attack_model = LogisticRegression(random_state=42)
attack_model.fit(X_attack_train, y_attack_train)
print("Attack model trained.\n")

print("--- 6. Running and Evaluating the Attack ---")
# This is the REAL test. We use our trained attack_model to
# predict membership in the *original target_model*.

# First, we get the confidence scores from the TARGET model
# for its *known members*...
target_train_proba = target_model.predict_proba(X_target_train)
target_train_labels = np.ones(len(X_target_train)) # Label = 1

# ...and for its *known non-members*.
target_test_proba = target_model.predict_proba(X_target_test)
target_test_labels = np.zeros(len(X_target_test))  # Label = 0

# Combine these to create the *attack test set*.
# This data has *never* been seen by the attack_model.
X_attack_test = np.concatenate((target_train_proba, target_test_proba), axis=0)
y_attack_test_actual = np.concatenate((target_train_labels, target_test_labels), axis=0)

# Run the attack!
y_attack_test_pred = attack_model.predict(X_attack_test)
y_attack_test_pred_proba = attack_model.predict_proba(X_attack_test)[:, 1]







print("--- 7. Attack Results ---")
accuracy = accuracy_score(y_attack_test_actual, y_attack_test_pred)
auc = roc_auc_score(y_attack_test_actual, y_attack_test_pred_proba)

print(f"Attack Accuracy: {accuracy * 100:.2f}%")
print(f"Attack AUC: {auc:.4f}\n")

print("A 'random guess' attack would have 50% accuracy.")
print("The closer this is to 100%, the more successful the attack.")
print("\nClassification Report for the Attack:")
print(classification_report(y_attack_test_actual, y_attack_test_pred, target_names=["Non-Member (0)", "Member (1)"]))




//////////////////////////////////////////////////////////////END GAME //////////////////////////////////////////////////////////////////





