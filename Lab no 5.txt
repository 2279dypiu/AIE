from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from lime.lime_tabular import LimeTabularExplainer
import numpy as np

iris = load_iris()
X = iris.data
y = iris.target

feature_names = iris.feature_names
class_names = iris.target_names

# 2. Train model
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)

from matplotlib import pyplot as plt
probs = model.predict_proba([X_test[10]])[0]
classes = iris.target_names

# Print them
print("Prediction probabilities:")
for c, p in zip(classes, probs):
    print(f"{c}: {p:.3f}")

# Optional: visualize them
plt.bar(classes, probs, color='skyblue')
plt.ylabel("Probability")
plt.title("Prediction probabilities for sample")
plt.show()

explainer = LimeTabularExplainer(
    X_train,
    feature_names=feature_names,
    class_names=class_names,
    discretize_continuous=True
)

exp = explainer.explain_instance(X_test[i], model.predict_proba, num_features=4, top_labels=3)

print("True class:", iris.target_names[y_test[i]])
print("Predicted class:", iris.target_names[model.predict([X_test[i]])[0]])

